{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "spy = pd.read_csv('SPY.csv', parse_dates=['Dt'])\n",
    "xlk = pd.read_csv('XLK.csv', parse_dates=['Dt'])\n",
    "xlb = pd.read_csv('XLB.csv', parse_dates=['Dt'])\n",
    "xlf = pd.read_csv('XLF.csv', parse_dates=['Dt'])\n",
    "data_sources = {'SPY': spy, 'XLK': xlk, 'XLB': xlb, 'XLF': xlf}\n",
    "\n",
    "lags = [5, 10, 21, 42]\n",
    "lag_tags = {5: '1W', 10: '2W', 21: '1M', 42: '2M'}\n",
    "\n",
    "def compute_returns(df, lags):\n",
    "    returns = {f'return_{lag}': df['Close'].pct_change(lag) for lag in lags}\n",
    "    return pd.DataFrame(returns)\n",
    "\n",
    "features = []\n",
    "for ticker, df in data_sources.items():\n",
    "    df.set_index('Dt', inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    returns = compute_returns(df, lags)\n",
    "    returns.columns = [f'{ticker}_return_{lag_tags[lag]}' for lag in lags]\n",
    "    features.append(returns)\n",
    "\n",
    "merged_df = pd.concat(features, axis=1).dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choose Lagged Returns of SPY and Other 3 Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "prediction_results = []\n",
    "\n",
    "for start in range(0, len(merged_df) - window_size, 21):\n",
    "    train_data = merged_df.iloc[start : start + window_size]\n",
    "    test_data = merged_df.iloc[start + window_size : start + window_size + 1]\n",
    "    \n",
    "    if test_data.empty:\n",
    "        break\n",
    "    \n",
    "    X_train, y_train = train_data.drop(columns=['SPY_return_1W']), train_data['SPY_return_1W']\n",
    "    X_test = test_data.drop(columns=['SPY_return_1W'])\n",
    "\n",
    "    model = make_pipeline(StandardScaler(), Ridge(alpha=1.0))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    prediction = model.predict(X_test)[0]\n",
    "    signal = 'Long' if prediction > 0 else 'Short'\n",
    "    prediction_results.append({'Date': test_data.index[0], 'Prediction': prediction, 'Signal': signal})\n",
    "\n",
    "signals_df = pd.DataFrame(prediction_results)\n",
    "signals_df.to_csv('momentum_signals.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calibrate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy.rename(columns={'Close': 'Close_SPY'}, inplace=True)\n",
    "xlb.rename(columns={'Close': 'Close_XLB'}, inplace=True)\n",
    "xlf.rename(columns={'Close': 'Close_XLF'}, inplace=True)\n",
    "merged_data = spy.merge(xlb, on='Dt', how='inner').merge(xlf, on='Dt', how='inner')\n",
    "\n",
    "merged_data['SPY_return'] = merged_data['Close_SPY'].pct_change()\n",
    "merged_data['XLB_return'] = merged_data['Close_XLB'].pct_change()\n",
    "merged_data['XLF_return'] = merged_data['Close_XLF'].pct_change()\n",
    "\n",
    "for lag in lags:\n",
    "    for ticker in ['SPY', 'XLB', 'XLF']:\n",
    "        merged_data[f'{ticker}_{lag_tags[lag]}'] = merged_data[f'{ticker}_return'].shift(lag)\n",
    "\n",
    "merged_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict the Next Day's Return and Make Short/Long Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_data[[col for col in merged_data.columns if 'return' in col and col != 'SPY_return']]\n",
    "y = merged_data['SPY_return']\n",
    "\n",
    "models = {\n",
    "    \"OLS\": LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=0.1),\n",
    "    'ElasticNet': ElasticNet(alpha=0.01, l1_ratio=0.5),\n",
    "    'Lasso': Lasso(alpha=0.01),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=1),\n",
    "}\n",
    "\n",
    "cumulative_returns = {name: pd.Series(dtype='float64') for name in models.keys()}\n",
    "train_size = 100\n",
    "step_size = 20\n",
    "test_size = len(merged_data) - train_size\n",
    "\n",
    "for start in range(0, test_size, step_size):\n",
    "    end = start + train_size\n",
    "    X_train, y_train = X.iloc[start:end], y.iloc[start:end]\n",
    "    X_test, y_test = X.iloc[end:end+step_size], y.iloc[end:end+step_size]\n",
    "\n",
    "    if y_test.isna().any():\n",
    "        continue\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        signals = np.where(y_pred > 0, 1, -1) \n",
    "        strategy_returns = signals * y_test\n",
    "\n",
    "        new_cumulative_returns = (1 + strategy_returns).cumprod()\n",
    "\n",
    "        new_cumulative_returns = new_cumulative_returns.dropna()\n",
    "        \n",
    "        if not new_cumulative_returns.empty:\n",
    "            cumulative_returns[name] = pd.concat([cumulative_returns[name], new_cumulative_returns])\n",
    "\n",
    "for name in models.keys():\n",
    "    final_return = cumulative_returns[name].iloc[-1] if not cumulative_returns[name].empty else \"nan\"\n",
    "    print(f\"{name} final cumulative return: {final_return}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate 5 Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for name in models.keys():\n",
    "    if not cumulative_returns[name].empty:\n",
    "        plt.plot(cumulative_returns[name].values, label=name)\n",
    "\n",
    "plt.title('Cumulative Returns of Different Models (Rolling Calibration)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis, OLS and Ridge Regression produced the highest cumulative returns, both at 1.205, which suggests that a simple linear model effectively captures the momentum patterns in the data. ElasticNet performed slightly better with a cumulative return of 1.208, likely benefiting from its balanced regularization approach. On the other hand, Lasso had a lower cumulative return of 1.056, possibly due to its high regularization, which may have overly penalized important signals. KNN showed a moderate return of 1.164, indicating that while non-linear models can be useful, further tuning of hyperparameters could improve performance. Overall, linear models—particularly Ridge Regression—seem to be the most effective for short-term momentum-based trading strategies in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
